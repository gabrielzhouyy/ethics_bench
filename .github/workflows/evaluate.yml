name: Ethics Bench Evaluation

on:
  push:
    branches: [main]
    paths:
      - 'scenario.toml'
      - 'src/**'
      - 'requirements.txt'
      - '.github/workflows/evaluate.yml'
  workflow_dispatch:
    inputs:
      white_agent_image:
        description: 'White agent image'
        required: false
        default: 'ghcr.io/gabrielzhouyy/white_agent:latest'
      green_agent_image:
        description: 'Green agent image'
        required: false
        default: 'ghcr.io/gabrielzhouyy/ethics_bench:latest'

jobs:
  evaluate:
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    permissions:
      contents: write
      packages: read
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      
      - name: Run evaluation
        env:
          WHITE_AGENT_IMAGE: ${{ inputs.white_agent_image || 'ghcr.io/gabrielzhouyy/white_agent:latest' }}
          GREEN_AGENT_IMAGE: ${{ inputs.green_agent_image || 'ghcr.io/gabrielzhouyy/ethics_bench:latest' }}
          GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
          WHITE_AGENT_URL: http://white-agent:9002  # Added explicit URL for white agent
        run: |
          python -m src.evaluate_runner \
            --white-image "$WHITE_AGENT_IMAGE" \
            --green-image "$GREEN_AGENT_IMAGE" \
            --output-dir . \
            --participant-name "white_agent"
      
      - name: Upload results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: evaluation-results
          path: |
            results/
            submissions/
          retention-days: 30
      
      - name: Print results summary
        if: always()
        run: |
          echo "=== Evaluation Summary ==="
          if [ -d results ]; then
            echo "Results saved to:"
            ls -lah results/ || echo "No results found"
            echo ""
            echo "Latest result:"
            ls -t results/*.json 2>/dev/null | head -1 | xargs --no-run-if-empty cat | python -m json.tool | head -50
          fi
